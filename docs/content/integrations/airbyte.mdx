---
title: "Using Dagster with Airbyte"
description: Integrate your Airbyte connections into Dagster.
---

# Using Airbyte with Dagster

Dagster can orchestrate your Airbyte connections, making it easy to chain an Airbyte sync with upstream or downstream steps in your workflow.

This guide focuses on how to work with Airbyte connections using Dagster's [software-defined asset (SDA)](/concepts/assets/software-defined-assets) framework.

---

## Airbyte connections and Dagster software-defined assets

An [Airbyte connection](https://docs.airbyte.com/understanding-airbyte/connections/) defines a series of data streams which are synced between a source and a destination. During a sync, each stream is replicated in the destination, typically as one or more tables. Dagster represents each of the replicas generated in the destination as a software-defined asset. This enables you to easily:

- Visualize the streams involved in an Airbyte connection and execute a sync from Dagster
- Define downstream computations which depend on replicas produced by Airbyte
- Track historical metadata and logs for each data stream
- Track data lineage through Airbyte and other tools

---

## Loading Airbyte assets into Dagster

The easiest way to get started using Airbyte with Dagster is to have Dagster automatically generate assets from your Airbyte project. This can be done in one of two ways:

- Load assets from Airbyte YAML configuration files, generated by Airbyte's [Octavia CLI](https://github.com/airbytehq/airbyte/tree/master/octavia-cli#what-is-octavia-cli)
- Load assets from an Airbyte instance via API, at initialization time

### Loading Airbyte assets from YAML config

To load Airbyte assets into Dagster from a set of YAML configuration files, specify the root YAML configuration folder, which contains the `sources`, `destinations`, and `connections` subfolders. Here, the YAML files are treated as the source of truth.

```python startafter=start_load_assets_from_airbyte_project endbefore=end_load_assets_from_airbyte_project file=/integrations/airbyte/airbyte.py dedent=4
from dagster_airbyte import load_assets_from_airbyte_project

airbyte_assets = load_assets_from_airbyte_project(project_dir="path/to/airbyte/project")
```

The `load_assets_from_airbyte_project` function parses the YAML metadata, generating a set of software-defined assets which reflect each of the data streams synced by your connections. Each connection has an associated [operation](https://docs.dagster.io/concepts/ops-jobs-graphs/ops#ops) which triggers a sync of that connection.

#### Adding a resource

Assets loaded from Airbyte require an `airbyte_resource`, which defines how to connect and interact with your Airbyte instance.

You can configure this resource and add it to your Airbyte assets by doing the following:

```python startafter=start_airbyte_project_config endbefore=end_airbyte_project_config file=/integrations/airbyte/airbyte.py dedent=4
from dagster_airbyte import airbyte_resource, load_assets_from_airbyte_project

from dagster import with_resources

airbyte_assets = with_resources(
    load_assets_from_airbyte_project(project_dir="path/to/airbyte/project"),
    {
        "airbyte": airbyte_resource.configured(
            {
                "host": "localhost",
                "port": "8000",
            }
        )
    },
)
```

### Loading Airbyte assets from Airbyte instance

To load Airbyte assets into Dagster from a live Airbyte instance, you will need to configure an Airbyte resource which defines how to connect to that instance. Here, the Airbyte instance is treated as the source of truth.

```python startafter=start_load_assets_from_airbyte_instance endbefore=end_load_assets_from_airbyte_instance file=/integrations/airbyte/airbyte.py dedent=4
from dagster_airbyte import airbyte_resource, load_assets_from_airbyte_instance

airbyte_instance = airbyte_resource.configured(
    {
        "host": "localhost",
        "port": "8000",
    }
)
airbyte_assets = load_assets_from_airbyte_instance(airbyte_instance)
```

The `load_assets_from_airbyte_instance` function retrieves a list of connection definitions via the Airbyte API, generating a set of software-defined assets which reflect each of the data streams synced by your connections. Each connection has an associated [operation](https://docs.dagster.io/concepts/ops-jobs-graphs/ops#ops) which triggers a sync of that connection.

The assets produced by this function are automatically bound the passed `airbyte_resource` to use at runtime.

---

## Scheduling Airbyte syncs

Once you have Airbyte assets, you can define a job that runs some or all of these assets on a schedule, triggering the underlying Airbyte sync:

```python startafter=start_schedule_assets endbefore=end_schedule_assets file=/integrations/airbyte/airbyte.py dedent=4
from dagster import ScheduleDefinition, define_asset_job, repository

run_everything_job = define_asset_job("run_everything", selection="*")

# only my_model and its children
run_something_job = define_asset_job("run_something", selection="my_connection*")

@repository
def my_repo():
    return [
        airbyte_assets,
        ScheduleDefinition(
            job=run_something_job,
            cron_schedule="@daily",
        ),
        ScheduleDefinition(
            job=run_everything_job,
            cron_schedule="@weekly",
        ),
    ]
```

Refer to the [Schedule documentation](/concepts/partitions-schedules-sensors/schedules#running-the-scheduler) for more info on running jobs on a schedule.

---

## Conclusion

If you find a bug or want to add a feature to the `dagster-airbyte` library, we invite you to [contribute](/community/contributing).

If you have questions on using Airbyte with Dagster, we'd love to hear from you:

<p align="center">
  <a href="https://dagster-slackin.herokuapp.com/" target="_blank">
    <Image
      alt="join-us-on-slack"
      src="/assets/join-us-on-slack.png"
      width="160"
      height="40"
    />
  </a>
</p>
